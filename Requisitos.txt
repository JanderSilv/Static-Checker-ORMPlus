+ Entradas: (Pág. 4)
1. Aceitar qualquer texto em ASCII e utilizar as regras da linguagem para analisar.
2. Não deverá ser solicitada a extensão do texto fonte na chamada de execução.
  2.1. Caso não seja passado a extensão, buscar na pasta raiz o nome do arquivo passado com a extensão .201
  2.2. Caso passe o diretório, busca no diretório indicado.

--------------------------------------------------------------------------------------------------------------------------

+ Saída: (Pág. 4 e 5)
1. A saída deve ser um arquivo com o relatório da análise léxica e um outro com o relatório da tabela de símbolos.
  1.1. Os arquivos gerados devem ter a extensão .LEX e .TAB respectivamente, com o nome do arquivo passado.
2. O arquivo .LEX deve mostrar a relação dos símbolos da linguagem que foram encontrados no texto fonte analisado, na ordem em que estes aparecerem e tantas vezes quantas tenham aparecido.
  2.1. Este relatório deve indicar no cabeçalho: o código identificador da equipe, os nomes, e-mails e telefones de todos os componentes da equipe que participaram da elaboração desta etapa do projeto.
  2.2. Para cada linha detalhe do relatório de análise léxica, devem ser exibidas no mínimo as informações: o elemento léxico formado (chamado de lexeme), o código do átomo correspondente a este elemento léxico e o índice deste símbolo na tabela de símbolos (quando for um símbolo que seja armazenado nesta estrutura de dados).
  2.3. Pode conter outras informações caso achar necessário ou relevante.
3. O arquivo .TAB deve mostrar todos os símbolos do tipo identificadores que foram armazenados na tabela de símbolos durante o processo de avaliação do texto fonte.
  3.1. O relatório deve refletir a última situação da tabela de símbolos após o término do processo de análise realizado.
  3.2. Para cada símbolo armazenado na tabela de símbolos devem ser relacionados todos os atributos dele com todos os valores que foram preenchidos durante o funcionamento do Static Checker.

--------------------------------------------------------------------------------------------------------------------------

+ Entregas do Projeto: (Pág. 5)

1. Serão 4 entregas:
  • Etapa 1 (PRJ): Projeto conceitual da implementação do compilador e simplificação da gramática da linguagem;
  • Etapa 2 (BRU): Documentação do processo de obtenção do autômato bruto equivalente à linguagem do projeto;
  • Etapa 3 (OTI): documentação do processo de obtenção do autômato ótimo equivalente à linguagem do projeto;
  • Etapa 4 (LEX): entrega da implementação completa do Static Checker funcionando com programa principal, a análise léxica e tabela de símbolos (fontes e executável).
2. As entregam devem ser realizadas no Classroom de maneira privada com um arquivo ZIP.
  2.1. O nome do arquivo deve ser o ID da equipe seguido do código da entrega.
  Ex: E01PRJ.ZIP
  2.2 Além do ZIP, enviar um TXT de nome ENTREGA contendo: código da equipe, nome de todos os componentes da equipe que participaram daquela etapa, acompanhados de telefones de contato e endereços de e-mail e a relação dos itens que compõem aquela entrega.

--------------------------------------------------------------------------------------------------------------------------

+ Analisador Léxico: (Pág. 8, 9 e 10)

1. No analisador léxico devem ser lidos todos os caracteres do texto fonte, um a um, e baseado nesta leitura devem ser montados os átomos que se encontram neste texto fonte de acordo com os padrões de formação de cada um deles e com a situação que ocorre em cada texto fonte. 
  1.1. Cada chamada ao analisador léxico tem por função formar apenas um átomo do texto fonte.
  1.2. A cada chamada, o analisador léxico é informado da posição corrente no texto fonte e deve ser capaz de formar o próximo átomo que existe após esta posição retornando esta informação para o programa chamador do analisador léxico. Esta leitura poderá ser implementada usando a técnica de bufferização de entrada com buffer de duas metades, embora não seja exigido.

2. A implementação do seu projeto não deve considerar diferenças entre letras maiúsculas e minúsculas. 
  2.1. O texto fonte fornecido como parâmetros pode conter letras maiúsculas e minúsculas, mas devem ser consideradas como se fossem todas maiúsculas.
  2.2. Os identificadores com diferença de caixa não serão considerados como símbolos distintos (caixa alta ou caixa baixa é o mesmo que maiúsculo ou minúsculo).

3. O texto fonte pode ser formado de qualquer sequência de caracteres. Alguns caracteres são caracteres válidos para a linguagem, outros caracteres são inválidos para a linguagem.

4. Os caracteres válidos são aqueles usados em alguma construção da linguagem (no padrão de formação de algum átomo da linguagem ou em construções auxiliares como comentários e arrumação do texto).
  4.1. Os espaços em branco, os comentários, marcas de tabulação (ASCII 09), caractere de fim de linha (ASCII 10), o de quebra de linha (ASCII 13), além de todos os caracteres usados na montagem de um átomo válido da linguagem, são considerados caracteres válidos da linguagem.

5. Os caracteres inválidos devem ser filtrados no processo de formação dos átomos.
  5.1. Este filtro é chamado de filtro de primeiro nível e não deve significar erro na execução do analisador léxico. Neste caso os caracteres inválidos são simplesmente desconsiderados do texto fonte sem funcionar como um delimitador permitindo que a formação do átomo continue.

6. Os espaços em branco existentes nos textos fontes normalmente funcionam como delimitadores na formação dos átomos para a maioria das linguagens. 
  6.1. No caso da linguagem ORMPlus2021-1, eles se encaixam na regra geral, ou seja, todos os caracteres válidos que não fizerem parte do padrão de formação do átomo que estiver sendo formado correntemente devem ser considerados como delimitadores para este processo de montagem de átomo. 
  6.2. Nos casos onde o espaço em branco não faça parte do padrão de formação do átomo sendo formado ele vai funcionar como um delimitador. 
  6.3. Nos casos onde o espaço em branco faça parte do padrão léxico de formação do átomo eles poderão ser considerados como parte do elemento léxico que está sendo formado. 
  6.4. Os espaços em branco adicionais, repetidos, devem ser filtrados do texto fonte.

7. Os comentários em ORMPlus2021-1 são fornecidos como recurso adicional da linguagem e não estão especificados na definição formal dada pela gramática. 
  7.1. Os comentários existentes nos textos fontes normalmente funcionam como delimitadores na formação dos átomos e neste caso deverão ser filtrados do texto para efeito das etapas posteriores do Static Checker. 
  7.2. Os comentários podem acontecer de duas formas nos textos fontes: ou como comentários de bloco ou como comentários de linha. No caso dos comentários de bloco eles devem ser iniciados com a cadeia “ /* “ (abre comentário) e finalizados com a cadeia “ */ ” (fecha comentário). Neste caso, se não existir a segunda cadeia “ */ ” fechando o comentário, todo o restante do programa fonte até o final de arquivo deverá ser considerado comentário. 
  7.3 Os comentários de linha podem ser iniciados com a cadeia “ // “ (inicia comentário de linha), devendo neste caso valer até o final da linha corrente. Se não existir o final de linha fechando o comentário, todo o restante do programa fonte até o final de arquivo deverá ser considerado comentário.

8. Na leitura do primeiro caractere válido, logo após a chamada do analisador léxico, é seguido um dos padrões léxicos existentes para a linguagem. Este padrão vai ser seguido até que se encontre algum caractere válido para a linguagem que não seja válido para o padrão de formação do átomo que está sendo montado. Ou seja, tudo o que não puder fazer parte deste átomo será considerado como delimitador, usando o critério do máximo comprimento possível, ou seja, enquanto o caractere lido puder fazer parte do átomo ele será considerado como parte do átomo que está sendo montado.

9. Para a linguagem ORMPlus2021-1, os átomos possuem um limite máximo de 30 caracteres válidos de tamanho.
  9.1. Todas as seqüências de caracteres válidos para a linguagem que respeitem a um determinado padrão de formação de átomo devem ser consideradas apenas até o limite máximo de 30 caracteres e após este limite devem ser desconsiderados para o átomo que está sendo formado no momento. 
    Ex: um nome de variável que tenha 100 caracteres válidos de tamanho será reconhecido pelo analisador léxico como sendo um átomo do tipo nome de variável com as 30 primeiras posições e o restante dos caracteres (os outros 65 caracteres) que poderiam fazer parte deste átomo nome de variável pelo padrão léxico de formação deverão ser desconsiderados do texto fonte. 
      • Apenas os caracteres não filtrados são contados para o limite de 30 caracteres de um átomo. 
      • A leitura deve continuar mesmo depois dos 30 primeiros caracteres até encontrar o ponto onde vai existir algum caractere delimitador para aquele átomo.
      • No limite de 30 caracteres para a formação do átomo, o analisador léxico deve estar atento para formar apenas átomos válidos para o padrão definido para aquele átomo. 
      • Algumas situações especiais devem ser tratadas como, por exemplo, forçar um final de cadeia na posição número 30, ou garantir que os números após truncar os elementos após a posição 30 irão formar construções coerentes e válidas para o padrão que foi usado. 
      • Os abre e fecha aspas são considerados como caractere válido na contabilização do tamanho do átomo.
      • Para os comentários não valem as regras de tamanho máximo de um átomo, já que neste caso não se trata de átomo da linguagem.

10. A cada chamada da rotina do analisador léxico serão utilizadas três informações: 
  1) a posição corrente do texto fonte que deve ser analisada no momento
  2) o código do átomo formado (parâmetro de retorno)
  3) o índice da tabela de símbolos onde o átomo foi gravado (apenas para os identificadores, também parâmetro de retorno)10.1. O átomo formado pode ser verificado, após a sua montagem, com a tabela de palavras e símbolos reservados que irá conter todas as palavras definidas da linguagem e com a tabela de símbolos, contendo todos os identificadores já reconhecidos.
  10.2. A análise léxica trabalhará sobre o arquivo texto com extensão .201 e irá gerar o relatório .LEX.

--------------------------------------------------------------------------------------------------------------------------

+ Analisador sintático: (Pág. 10)

1. Funciona como programa principal do compilador usando o esquema de implementação do sintax driven.
  1.1. Somente as atividades de controlador, inicializador, emissão de relatórios, as bases para a verificação da ordem dos átomos (pelos autômatos ótimos) e o controle de escopo para o correto funcionamento do analisador precisam ser implementadas.
  1.2. Atividades:
    • Solicitação ao usuário do arquivo fonte a ser compilado
    • Abertura do arquivo fonte
    • Inicialização das estruturas de dados da tabela de símbolos e da tabela de palavras e símbolos reservados
    • Chamadas ao analisador léxico
    • Controle de escopo para a formação dos átomos
    • Emissão dos relatórios .LEX e .TAB

--------------------------------------------------------------------------------------------------------------------------

+ Tabela de Símbolos: (Pág. 10 e 11)

1. Apenas os átomos identificadores serão armazenados na tabela de símbolos. 
  1.1. As palavras e símbolos reservados da linguagem ORMPlus2021-1 deverão constar numa tabela especial separada da tabela de símbolos, que será chamada de tabela de palavras e símbolos reservados e que deverá estar previamente carregada antes do início da primeira análise. 
  1.2. A tabela de palavras e símbolos reservados será fixa para todos os programas analisados. 
  1.3. A tabela de símbolos irá variar a depender dos átomos existentes no texto fonte que estiver sendo analisado. 
  1.4. A tabela de símbolos do projeto irá conter os seguintes atributos: 
    • Número da entrada da tabela de símbolos 
    • Código do átomo lexeme
    • Quantidade de caracteres antes da truncagem 
    • Quantidade de caracteres depois da truncagem
    • Tipo do símbolo e as cinco primeiras linhas onde o símbolo aparece.

2. Os números das entradas indicarão os índices de armazenamento daqueles símbolos na tabela e são usados em todo o processo de análise do texto fonte. 
 2.1. Cada símbolo (lexeme com o mesmo significado) na tabela de símbolos deverá ter um endereço único, ou seja, não existirão duas entradas na tabela de símbolos para o mesmo símbolo. Esta informação não deve ser modificada durante o processo de análise.

3. Os códigos dos átomos, correspondentes aos tipos dos símbolos encontrados no texto fonte, seguirão a relação de códigos de átomos fornecida na especificação da linguagem e constante no item 10 desta documentação (apenas para os átomos identificadores, que são os símbolos guardados na tabela de símbolos). Esta informação não deve ser modificada durante a análise.

4. Os lexemes devem ser guardados com apenas os 30 primeiros caracteres válidos da linguagem que aparecem no texto fonte. Esta informação não deve ser modificada durante a análise.

5. Os tipos dos símbolos deverão ser preenchidos apenas para os identificadores em que fizer sentido (Identifier, Function, Integer-Number, Float-Number, Constant-String, Character). Os tipos podem um dos seguintes: PFO (ponto flutuante) INT (inteiro), STR (string), CHC (character), BOO (booleano), VOI (void), APF,(array de ponto flutuante) AIN (array de inteiro), AST (array de string), ACH (array de character), ABO (array de booleano). Esta informação não deve ser modificada durante a análise.

6. As quantidades de caracteres do lexeme levando em conta apenas os 30 primeiros caracteres válidos irão armazenar para cada símbolo a quantidade de caracteres válidos antes do processo de truncagem acontecer. 
  6.1. Não devem ser levados em consideração os caracteres filtrados na montagem do átomo (caracteres inválidos da linguagem). 
  6.2. Para as cadeias considerar as aspas simples ou duplas como parte do tamanho do átomo. Esta informação pode ser modificada durante a análise. 
  6.3. As quantidades de caracteres do lexeme sem levar em conta apenas os 30 primeiros caracteres válidos irão armazenar para cada símbolo a quantidade de caracteres independente do processo de truncagem que tenha acontecido. 
  6.4. Não devem ser levados em consideração os caracteres filtrados na montagem do átomo (caracteres inválidos da linguagem). 
  6.5. Para as cadeias considerar as aspas simples ou duplas como parte do tamanho do átomo. Esta informação pode ser modificada durante a análise.

7. Os números das linhas onde o símbolo aparece pelas primeiras cinco vezes serão guardados com base no controle de linhas a ser efetuado sobre o texto fonte. 
  7.1. Para este controle de linhas não devem ser descartadas as linhas de comentários existentes no texto. 
  7.2. Deve ser considerada a linha onde o símbolo começa para os casos em que um símbolo possa ser definido em mais de uma linha. Esta informação pode ser modificada durante a análise.

--------------------------------------------------------------------------------------------------------------------------

+ Autômatos: (Pág. 12)

1. As equipes vão transformar a linguagem fornecida nesta especificação em seus autômatos ótimos equivalentes (IMPORTANTE: usando apenas o nível sintático de definição sintática da linguagem, ou seja, até o item 11 desta especificação). 
  1.1. Estes autômatos ótimos servirão para a implementação do analisador sintático. 
  1.2. A linguagem deverá ter sido transformada em N regras de gramática que produzirá N autômatos equivalentes. 
  1.3. Deve-se ter ao final de todo o processo N autômatos distintos que serão simplificados através das técnicas de obtenção de autômatos ótimos. O conjunto destes N autômatos é o reconhecedor da linguagem e a sua implementação seria o analisador sintático da linguagem ORMPlus2021-1.

2. No processo de simplificação deve-se considerar todos os átomos da linguagem como sendo símbolos terminais do ponto de vista do analisador sintático, mesmo que estes sejam símbolos não terminais na especificação da linguagem. Isto acontece com os símbolos identificadores, já que eles são detalhados ainda na linguagem para determinação dos padrões léxicos de formação dos átomos.

3. Nas regras de gramática resultantes e nos autômatos brutos e ótimos encontrados existirão referências aos outros autômatos e regras da linguagem (um dos outros N), que deverão ser encarados neste ponto como um outro átomo qualquer da linguagem. 
  3.1. Os códigos dos autômatos serão iniciados em 90, até o código 90+N (dependendo da quantidade de autômatos resultantes do processo de obtenção do autômato ótimo).